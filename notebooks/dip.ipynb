{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch\n",
    "A goal worth seeking is to be able to use the results from one-shot denoising or\n",
    "inpainting in order to quickly evaluate different network architectures. This \n",
    "would allow the speed up of network architecture search.\n",
    "\n",
    "To use such one-shot evaluations, it must be known what qualities of a network\n",
    "they measure. \n",
    "\n",
    "Some possible ideas:\n",
    "* good denoising results suggest that when learning algorithm is applied, the\n",
    "  learning process descends to optimum parameter sets which have one or both of \n",
    "  the following properties:\n",
    "    1. earlier layers contribute most to the output.\n",
    "    2. a large number of parameters contribute to the output.\n",
    "\n",
    "\n",
    "Some questions:\n",
    "* why haven't I had any success training with SGD, but success with Adam?\n",
    "* why are the results so sensitive to learning rate?\n",
    "* maybe the effectiveness is a better indicator of appropriate learning rate \n",
    "  (rather than being indicative of a good network structure). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate results from \"Deep Image Prior\" paper\n",
    "Try to investigate some of the following claims and questions.\n",
    "\n",
    "## Learning differences between layers explains one-shot denoising results.\n",
    "Proposition 1: back-propagation with gradient descent favors the stabilization\n",
    "of earlier layers before later layers. \n",
    "\n",
    "In more detail: the gradient of parameters in earlier layers must become small \n",
    "enough so that updates to  parameters in later layers will reduce the loss in \n",
    "expectation. As the gradient of earlier parameters reduces from large to small, \n",
    "the probability of a later parameter making a constructive contribution \n",
    "(reducing loss) increases from 50% towards 100%. \n",
    "\n",
    "Proposition 2: without contribution from the final layer, it is not possible to\n",
    "recreate single pixel noise. without contribution from the second last layer,\n",
    "it is not possible to recreate noise blocks of size 2x2. \n",
    "\n",
    "Argument:\n",
    "Proposition 1\n",
    "Proposition 2\n",
    "Therefore, a network's ability to model noise improves as training stabilizes. \n",
    "\n",
    "There is no notion of \"naturalness\" covered by this argument.\n",
    "\n",
    "### Experiment\n",
    "Train a network to output a noisy image from input noise.\n",
    "Measure:\n",
    "* the update distance for all layers. \n",
    "* the contribution distribution for the last layer.\n",
    "* the output accuracy.\n",
    "* the output accuracy for the noisy pixels.\n",
    "\n",
    "#### Evidence for proposition 1\n",
    "Approximate layer stability with the update distance for each layer. Might need\n",
    "some normalization. Fix some stability threshold. A strong relationship between \n",
    "layer number and time until reaching the  stability threshold is evidence for \n",
    "proposition 1.\n",
    "\n",
    "#### Evidence for proposition 2 \n",
    "If there is a strong positive relationship between the accuracy for the noisy \n",
    "pixels and the contribution distribution for the last layer-this is evidence \n",
    "for proposition 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
